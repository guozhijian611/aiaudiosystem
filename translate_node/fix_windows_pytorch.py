#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Windows PyTorch GPUä¿®å¤è„šæœ¬
ä¸“é—¨ç”¨äºåœ¨Windowsä¸Šä¿®å¤PyTorch GPUæ”¯æŒé—®é¢˜
"""

import os
import sys
import subprocess
import platform

def check_system():
    """æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯"""
    print("=" * 60)
    print("1. ç³»ç»Ÿä¿¡æ¯æ£€æŸ¥")
    print("=" * 60)
    
    system_info = {
        'system': platform.system(),
        'machine': platform.machine(),
        'processor': platform.processor(),
        'python_version': sys.version,
        'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'None')
    }
    
    for key, value in system_info.items():
        print(f"{key}: {value}")
    
    return system_info['system'].lower() == 'windows'

def check_cuda_installation():
    """æ£€æŸ¥CUDAå®‰è£…"""
    print("\n" + "=" * 60)
    print("2. CUDAå®‰è£…æ£€æŸ¥")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥nvidia-smiå‘½ä»¤
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, shell=True)
        if result.returncode == 0:
            print("âœ“ NVIDIAé©±åŠ¨å·²å®‰è£…")
            print("NVIDIA-SMIè¾“å‡º:")
            print(result.stdout[:500] + "..." if len(result.stdout) > 500 else result.stdout)
            return True
        else:
            print("âœ— nvidia-smiå‘½ä»¤å¤±è´¥")
            return False
    except FileNotFoundError:
        print("âœ— nvidia-smiå‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·å®‰è£…NVIDIAé©±åŠ¨")
        return False
    except Exception as e:
        print(f"âœ— CUDAæ£€æŸ¥å¤±è´¥: {e}")
        return False

def get_cuda_version():
    """è·å–CUDAç‰ˆæœ¬"""
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, shell=True)
        if result.returncode == 0:
            output = result.stdout
            # è§£æCUDAç‰ˆæœ¬
            for line in output.split('\n'):
                if 'release' in line.lower():
                    version = line.split('release')[1].split(',')[0].strip()
                    print(f"âœ“ CUDAç‰ˆæœ¬: {version}")
                    return version
        else:
            print("âš  nvccå‘½ä»¤ä¸å¯ç”¨ï¼Œå¯èƒ½åªå®‰è£…äº†è¿è¡Œæ—¶")
            return "unknown"
    except:
        print("âš  æ— æ³•è·å–CUDAç‰ˆæœ¬")
        return "unknown"

def uninstall_current_pytorch():
    """å¸è½½å½“å‰çš„PyTorch"""
    print("\n" + "=" * 60)
    print("3. å¸è½½å½“å‰PyTorch")
    print("=" * 60)
    
    packages_to_remove = [
        'torch',
        'torchaudio',
        'torchvision'
    ]
    
    for package in packages_to_remove:
        try:
            print(f"å¸è½½ {package}...")
            result = subprocess.run([
                sys.executable, '-m', 'pip', 'uninstall', package, '-y'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"âœ“ {package} å¸è½½æˆåŠŸ")
            else:
                print(f"âš  {package} å¸è½½å¤±è´¥æˆ–æœªå®‰è£…: {result.stderr}")
        except Exception as e:
            print(f"âœ— {package} å¸è½½å¼‚å¸¸: {e}")

def install_pytorch_gpu():
    """å®‰è£…GPUç‰ˆæœ¬çš„PyTorch"""
    print("\n" + "=" * 60)
    print("4. å®‰è£…GPUç‰ˆæœ¬PyTorch")
    print("=" * 60)
    
    # æä¾›å¤šä¸ªCUDAç‰ˆæœ¬é€‰é¡¹
    cuda_options = {
        '1': ('cu118', 'CUDA 11.8'),
        '2': ('cu121', 'CUDA 12.1'),
        '3': ('cu124', 'CUDA 12.4'),
        '4': ('cpu', 'CPUç‰ˆæœ¬ï¼ˆæ— GPUåŠ é€Ÿï¼‰')
    }
    
    print("è¯·é€‰æ‹©CUDAç‰ˆæœ¬:")
    for key, (version, desc) in cuda_options.items():
        print(f"  {key}. {desc}")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
    
    if choice in cuda_options:
        cuda_version, desc = cuda_options[choice]
        print(f"é€‰æ‹©äº†: {desc}")
        
        if cuda_version == 'cpu':
            install_cmd = [
                sys.executable, '-m', 'pip', 'install', 
                'torch', 'torchaudio', '--index-url', 
                'https://download.pytorch.org/whl/cpu'
            ]
        else:
            install_cmd = [
                sys.executable, '-m', 'pip', 'install', 
                'torch', 'torchaudio', '--index-url', 
                f'https://download.pytorch.org/whl/{cuda_version}'
            ]
        
        print(f"æ‰§è¡Œå®‰è£…å‘½ä»¤: {' '.join(install_cmd)}")
        
        try:
            result = subprocess.run(install_cmd, capture_output=True, text=True)
            if result.returncode == 0:
                print("âœ“ PyTorchå®‰è£…æˆåŠŸ")
                return True
            else:
                print(f"âœ— PyTorchå®‰è£…å¤±è´¥: {result.stderr}")
                return False
        except Exception as e:
            print(f"âœ— PyTorchå®‰è£…å¼‚å¸¸: {e}")
            return False
    else:
        print("æ— æ•ˆé€‰æ‹©")
        return False

def test_pytorch_gpu():
    """æµ‹è¯•PyTorch GPUæ”¯æŒ"""
    print("\n" + "=" * 60)
    print("5. æµ‹è¯•PyTorch GPUæ”¯æŒ")
    print("=" * 60)
    
    try:
        import torch
        print(f"âœ“ PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        cuda_available = torch.cuda.is_available()
        print(f"CUDAå¯ç”¨: {cuda_available}")
        
        if cuda_available:
            device_count = torch.cuda.device_count()
            print(f"âœ“ GPUè®¾å¤‡æ•°é‡: {device_count}")
            
            for i in range(device_count):
                device_name = torch.cuda.get_device_name(i)
                device_props = torch.cuda.get_device_properties(i)
                memory_total = device_props.total_memory / 1024**3
                print(f"  GPU {i}: {device_name}")
                print(f"    æ€»å†…å­˜: {memory_total:.1f}GB")
                print(f"    è®¡ç®—èƒ½åŠ›: {device_props.major}.{device_props.minor}")
            
            # æµ‹è¯•GPUè®¡ç®—
            print("\næµ‹è¯•GPUè®¡ç®—...")
            x = torch.randn(1000, 1000, device='cuda')
            y = torch.randn(1000, 1000, device='cuda')
            z = torch.matmul(x, y)
            print("âœ“ GPUçŸ©é˜µè¿ç®—æµ‹è¯•é€šè¿‡")
            
            return True
        else:
            print("âœ— CUDAä¸å¯ç”¨")
            return False
            
    except ImportError:
        print("âœ— PyTorchå¯¼å…¥å¤±è´¥")
        return False
    except Exception as e:
        print(f"âœ— PyTorchæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_faster_whisper():
    """æµ‹è¯•faster-whisper GPUæ”¯æŒ"""
    print("\n" + "=" * 60)
    print("6. æµ‹è¯•faster-whisper GPUæ”¯æŒ")
    print("=" * 60)
    
    try:
        from faster_whisper import WhisperModel
        print("âœ“ faster-whisperå¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•GPUæ¨¡å‹åˆ›å»º
        try:
            print("æµ‹è¯•åˆ›å»ºGPUæ¨¡å‹...")
            model = WhisperModel("tiny", device="cuda", compute_type="float16")
            print("âœ“ GPUæ¨¡å‹åˆ›å»ºæˆåŠŸ (float16)")
            del model
            
            model = WhisperModel("tiny", device="cuda", compute_type="float32")
            print("âœ“ GPUæ¨¡å‹åˆ›å»ºæˆåŠŸ (float32)")
            del model
            
            return True
            
        except Exception as e:
            print(f"âœ— GPUæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            
            # å°è¯•CPUæ¨¡å‹
            try:
                print("å°è¯•CPUæ¨¡å‹...")
                model = WhisperModel("tiny", device="cpu", compute_type="float32")
                print("âœ“ CPUæ¨¡å‹åˆ›å»ºæˆåŠŸ")
                del model
                return False  # GPUå¤±è´¥ä½†CPUæˆåŠŸ
            except Exception as e2:
                print(f"âœ— CPUæ¨¡å‹ä¹Ÿå¤±è´¥: {e2}")
                return False
                
    except ImportError as e:
        print(f"âœ— faster-whisperå¯¼å…¥å¤±è´¥: {e}")
        return False

def update_environment_config():
    """æ›´æ–°ç¯å¢ƒé…ç½®"""
    print("\n" + "=" * 60)
    print("7. æ›´æ–°ç¯å¢ƒé…ç½®")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥.envæ–‡ä»¶
        env_file = ".env"
        config_updates = []
        
        # æ ¹æ®GPUæµ‹è¯•ç»“æœæ¨èé…ç½®
        import torch
        if torch.cuda.is_available():
            device_props = torch.cuda.get_device_properties(0)
            if device_props.major >= 7:  # VoltaåŠä»¥ä¸Šæ¶æ„
                recommended_config = {
                    'WHISPER_DEVICE': 'cuda',
                    'WHISPER_COMPUTE_TYPE': 'float16'
                }
                print("âœ“ æ£€æµ‹åˆ°æ”¯æŒfloat16çš„GPUï¼Œæ¨èä½¿ç”¨GPU + float16")
            else:
                recommended_config = {
                    'WHISPER_DEVICE': 'cuda', 
                    'WHISPER_COMPUTE_TYPE': 'float32'
                }
                print("âš  GPUä¸æ”¯æŒé«˜æ•ˆfloat16ï¼Œæ¨èä½¿ç”¨GPU + float32")
        else:
            recommended_config = {
                'WHISPER_DEVICE': 'cpu',
                'WHISPER_COMPUTE_TYPE': 'float32'
            }
            print("âš  GPUä¸å¯ç”¨ï¼Œæ¨èä½¿ç”¨CPU + float32")
        
        print("\næ¨èçš„ç¯å¢ƒå˜é‡:")
        for key, value in recommended_config.items():
            print(f"  {key}={value}")
        
        # è¯¢é—®æ˜¯å¦æ›´æ–°é…ç½®æ–‡ä»¶
        if os.path.exists(env_file):
            update = input(f"\næ˜¯å¦æ›´æ–° {env_file} é…ç½®æ–‡ä»¶? (y/N): ").lower().strip()
            if update == 'y':
                # è¯»å–ç°æœ‰é…ç½®
                with open(env_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ›´æ–°é…ç½®
                for key, value in recommended_config.items():
                    if f"{key}=" in content:
                        # æ›¿æ¢ç°æœ‰é…ç½®
                        import re
                        pattern = f"^{key}=.*$"
                        replacement = f"{key}={value}"
                        content = re.sub(pattern, replacement, content, flags=re.MULTILINE)
                    else:
                        # æ·»åŠ æ–°é…ç½®
                        content += f"\n{key}={value}"
                
                # å†™å›æ–‡ä»¶
                with open(env_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                print(f"âœ“ é…ç½®æ–‡ä»¶å·²æ›´æ–°")
                return True
        else:
            create = input(f"\næ˜¯å¦åˆ›å»º {env_file} é…ç½®æ–‡ä»¶? (y/N): ").lower().strip()
            if create == 'y':
                config_content = "# Translate Node é…ç½®\n"
                for key, value in recommended_config.items():
                    config_content += f"{key}={value}\n"
                
                with open(env_file, 'w', encoding='utf-8') as f:
                    f.write(config_content)
                
                print(f"âœ“ é…ç½®æ–‡ä»¶å·²åˆ›å»º")
                return True
        
        print("è·³è¿‡é…ç½®æ–‡ä»¶æ›´æ–°")
        return True
        
    except Exception as e:
        print(f"âœ— é…ç½®æ›´æ–°å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("Windows PyTorch GPUä¿®å¤å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥ç³»ç»Ÿ
    is_windows = check_system()
    if not is_windows:
        print("âš  æ­¤è„šæœ¬ä¸“ä¸ºWindowsè®¾è®¡")
        return
    
    # æ£€æŸ¥CUDA
    cuda_installed = check_cuda_installation()
    if cuda_installed:
        get_cuda_version()
    else:
        print("âš  å»ºè®®å…ˆå®‰è£…NVIDIAé©±åŠ¨å’ŒCUDAå·¥å…·åŒ…")
        proceed = input("æ˜¯å¦ç»§ç»­å®‰è£…CPUç‰ˆæœ¬çš„PyTorch? (y/N): ").lower().strip()
        if proceed != 'y':
            return
    
    # å¸è½½å½“å‰PyTorch
    uninstall_current_pytorch()
    
    # å®‰è£…æ–°çš„PyTorch
    pytorch_installed = install_pytorch_gpu()
    if not pytorch_installed:
        print("âœ— PyTorchå®‰è£…å¤±è´¥")
        return
    
    # æµ‹è¯•PyTorch
    pytorch_gpu_ok = test_pytorch_gpu()
    
    # æµ‹è¯•faster-whisper
    faster_whisper_ok = test_faster_whisper()
    
    # æ›´æ–°é…ç½®
    config_ok = update_environment_config()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ä¿®å¤æ€»ç»“")
    print("=" * 60)
    print(f"CUDAé©±åŠ¨: {'âœ“' if cuda_installed else 'âœ—'}")
    print(f"PyTorch GPU: {'âœ“' if pytorch_gpu_ok else 'âœ—'}")
    print(f"Faster-Whisper: {'âœ“' if faster_whisper_ok else 'âœ—'}")
    print(f"é…ç½®æ›´æ–°: {'âœ“' if config_ok else 'âœ—'}")
    
    if pytorch_gpu_ok and faster_whisper_ok:
        print("\nğŸ‰ GPUæ”¯æŒä¿®å¤å®Œæˆï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. é‡å¯translate_nodeæœåŠ¡")
        print("2. è¿è¡Œ python test_gpu_support.py éªŒè¯ç»“æœ")
    elif pytorch_installed:
        print("\nâš ï¸ PyTorchå·²å®‰è£…ä½†GPUæ”¯æŒå¯èƒ½æœ‰é—®é¢˜")
        print("å»ºè®®æ£€æŸ¥NVIDIAé©±åŠ¨å’ŒCUDAç‰ˆæœ¬å…¼å®¹æ€§")
    else:
        print("\nâŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 