# ==================== 增强说话人分离配置 ====================
# RabbitMQ配置
RABBITMQ_HOST=10.0.0.130
RABBITMQ_PORT=5672
RABBITMQ_USERNAME=admin
RABBITMQ_PASSWORD=admin
RABBITMQ_VIRTUAL_HOST=/

# 队列名称
QUEUE_NAME=transcribe_queue

# 后端API配置
API_BASE_URL=http://10.0.0.130:8787
API_UPLOAD_ENDPOINT=/queue/upload
API_CALLBACK_ENDPOINT=/queue/callback

# 工作目录配置
WORK_DIR=./work
TEMP_DIR=./temp
LOG_LEVEL=INFO

# WhisperX转写配置
WHISPER_MODEL=large-v3
WHISPER_LANGUAGE=auto
WHISPER_DEVICE=auto
WHISPER_COMPUTE_TYPE=float16
WHISPER_BATCH_SIZE=2

# ==================== 增强说话人分离配置 ====================
ENABLE_DIARIZATION=true

# 🔥 推荐配置1：最新Pyannote模型 (最简单升级)
DIARIZATION_MODEL=pyannote/speaker-diarization@2.1
DIARIZATION_BACKEND=pyannote

# 🔥 推荐配置2：WeSpeaker模型 (效果更好，需要额外安装)
# DIARIZATION_MODEL=wespeaker/wespeaker-voxceleb-resnet34-LM
# DIARIZATION_BACKEND=wespeaker

# 🔥 推荐配置3：SpeechBrain模型 (专业级)
# DIARIZATION_MODEL=speechbrain/spkrec-ecapa-voxceleb
# DIARIZATION_BACKEND=speechbrain

# Hugging Face Token (必需!)
HF_TOKEN=your_huggingface_token_here

# 说话人数量配置 (对双人对话优化)
MIN_SPEAKERS=2
MAX_SPEAKERS=2

# 高级参数调优
SPEAKER_SIMILARITY_THRESHOLD=0.4    # 降低阈值，更容易区分相似声音
MINIMUM_SEGMENT_DURATION=0.3        # 最小段落时长，避免过短切分

# 语言对齐配置
ENABLE_ALIGNMENT=true
ALIGNMENT_MODEL=WAV2VEC2_ASR_LARGE_LV60K_960H

# 处理限制配置
MAX_AUDIO_DURATION=3600
PROCESSING_TIMEOUT=7200
CHUNK_DURATION=600

# 输出格式配置
OUTPUT_FORMAT=json
INCLUDE_TIMESTAMPS=true
INCLUDE_CONFIDENCE=true

# 模型缓存配置
MODEL_CACHE_DIR=./models
DISABLE_UPDATE=true

# 队列配置
QUEUE_TTL=3600000
QUEUE_DURABLE=true

# 其他配置
MAX_WORKERS=1
DOWNLOAD_TIMEOUT=300

# WhisperX路径配置
WHISPERX_PATH=./whisperX

# ==================== 使用说明 ====================
# 1. 简单升级：取消注释 pyannote@2.1 配置
# 2. 更好效果：安装 wespeaker 并使用相应配置
#    pip install wespeaker
# 3. 专业级：安装 speechbrain 并使用相应配置
#    pip install speechbrain
# 4. 记得设置有效的 HF_TOKEN
# 5. 对于双人对话，设置 MIN_SPEAKERS=2, MAX_SPEAKERS=2 